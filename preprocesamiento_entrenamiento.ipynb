{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Preprocesamiento_Entrenamiento.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/adawolfs/02684920abf29d96e707d6ca9aec644a/preprocesamiento_entrenamiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbDYYvWkRMwe",
        "colab_type": "text"
      },
      "source": [
        "# CNN en Español\n",
        "\n",
        "Este notebook esta destinado a servir como ejemplo practico para demostrar el funcionamiento de una red neuronal convolucional.\n",
        "\n",
        "El ejemplo utilizado es meramente didactico, pero explica de buena manera los siguietes aspectos:\n",
        "\n",
        "- Recolección de información\n",
        "- Proprocesamiento de data\n",
        "- Preparación de data de entrenamiento y de prueba\n",
        "- Diseño de una Red Neuronal\n",
        "- Entrenamiento de Red Neuronal\n",
        "- Validación y test de el Modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcmJzkwHCU1f",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "!git clone https://github.com/adawolfs/CNN_en_espanol.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIOXOuKzt9Ui",
        "colab_type": "text"
      },
      "source": [
        "# Resize de imagenes\n",
        "\n",
        "Ya que la data debe de estar normalizada ejecutaremos un script que se encargara de hacer la primera manipulación de las imagenes para darles un tamaño estandard.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "122XGddrCP9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as ptl # Utilizada para visualización de data\n",
        "from PIL import Image # Utilizada para manipulación de Imagenes\n",
        "from pathlib import Path # Utilizada para manipulación de archivos\n",
        "import random # emmmm Random!\n",
        "import shutil # Path tiene sus limitantes...\n",
        "\n",
        "IMAGE_RESIZE_PX = 64\n",
        "\n",
        "def print_image(img):\n",
        "  ptl.imshow(img)\n",
        "  ptl.axis('on')\n",
        "  ptl.show()\n",
        "\n",
        "def resize_images(source_dir, target_dir):\n",
        "  \"\"\"\n",
        "  resize_images\n",
        "  Esta función hace un resize de todas las imagenes en source_dir,\n",
        "  y las almacena utilizando valores numericos dentro de target_dir\n",
        "\n",
        "  se espera que source_dir tenga la siguiente estructura:\n",
        "  source_dir/\n",
        "   - dir01/\n",
        "   -- image.jpg\n",
        "   -- image1.jpg\n",
        "   -- imagexx.jpg\n",
        "   - dir02/\n",
        "   -- image.jpg\n",
        "   -- image1.jpg\n",
        "   -- imagexx.jpg\n",
        "   - dir03\n",
        "   ...\n",
        "  \"\"\"\n",
        "  source_dir = Path(source_dir)\n",
        "  target_dir = Path(target_dir)\n",
        "\n",
        "  try:\n",
        "    target_dir.mkdir()\n",
        "  except FileExistsError:\n",
        "    print(\"Directorio destino ya existe.\")\n",
        "    return\n",
        "\n",
        "  for dir in source_dir.iterdir():\n",
        "    print(f\"Directorio: {dir.name}\")\n",
        "    x = 0\n",
        "    for image in dir.iterdir():\n",
        "      #print(f\"Resizing: {image.name}\")\n",
        "      img = Image.open(image)\n",
        "      img = img.convert(\"RGB\")\n",
        "      \n",
        "      if x<5 :\n",
        "        print_image(img)\n",
        "\n",
        "      img = img.resize((IMAGE_RESIZE_PX,IMAGE_RESIZE_PX))\n",
        "      if x<5 :\n",
        "        print_image(img)\n",
        "\n",
        "      img.save(target_dir/f\"{dir.name}_{x}.jpg\")\n",
        "      x = x+1\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j3LKLlqUVcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf CNN_en_espanol/data/resized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmf7AzvkCP9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " resize_images(\"CNN_en_espanol/data/original\", \"CNN_en_espanol/data/resized\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCYQCUmNuZe-",
        "colab_type": "text"
      },
      "source": [
        "# Generación de imagenes \n",
        "Ya que los ejemplos son limitados utilizaremos el siguiente script para generar multiples variaciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTX3iZmjCP9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import numpy as np\n",
        "def generate_images(source_path, target_path, generations):\n",
        "  \"\"\"\n",
        "  Este metodo generará imagees extra con distintas variaciones de las\n",
        "  imagenes originales con la inteción de ayudar al modelo a generalizar y\n",
        "  no hacer un sobre entrenamiento (overfitting) sobre la data\n",
        "  \"\"\"\n",
        "  ## https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n",
        "  datagen = ImageDataGenerator(\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.2, \n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    channel_shift_range = 10,\n",
        "    fill_mode= 'nearest'\n",
        "  )\n",
        "  source_path = Path(source_path)\n",
        "  target_path = Path(target_path)\n",
        "    \n",
        "  if target_path.exists():\n",
        "    print(\"Target already exists, please delete it.\")\n",
        "    return 0\n",
        "\n",
        "  target_path.mkdir(parents=True)\n",
        "      \n",
        "  # Se hace una busqueda sobre todas las imagenes\n",
        "  for image in source_path.iterdir():\n",
        "    image_name, image_ext = image.name.split(\".\")\n",
        "    img = load_img(image)\n",
        "    img = img_to_array(img) # Se transforma al imagen en un array manipulable\n",
        "    img = img.reshape((1,) + img.shape)\n",
        "    #img = np.array([image])\n",
        "    i = 0\n",
        "    for batch in datagen.flow(img, batch_size=1, save_to_dir=target_path, save_prefix=image_name, save_format=\"jpg\"):\n",
        "      i = i+1\n",
        "      if i >= generations:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5icbK5DdZQeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf CNN_en_espanol/data/generated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnNU8g6zCP90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_images(\"CNN_en_espanol/data/resized\", \"CNN_en_espanol/data/generated\", 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovrmZ_S8DcpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo \"Imagenes orignales de entrenamiento: $(ls -la CNN_en_espanol/data/resized | wc -l)\"\n",
        "!echo \"Imagenes generadas de entrenamiento: $(ls -la CNN_en_espanol/data/generated | wc -l)\" \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3dFvb0Bu0Mx",
        "colab_type": "text"
      },
      "source": [
        "# Cargar imagenes y sus respectivos labels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaynhWtWCP94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from pathlib import Path\n",
        "categories = ['bulbasaur', 'charmander', 'squirtle']\n",
        "\n",
        "def img_set(images_path, test_size):    \n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "\n",
        "    images_path = Path(images_path)\n",
        "    \n",
        "    for img in images_path.iterdir():\n",
        "        image = load_img(img)\n",
        "        image = img_to_array(image)\n",
        "        label = categories.index(img.name.split('_')[0])\n",
        "      \n",
        "        if len(test_images) < test_size and random.randint(0,255) < 100:\n",
        "          test_labels.append(label)\n",
        "          test_images.append(image)\n",
        "        else:\n",
        "          train_labels.append(label)\n",
        "          train_images.append(image)\n",
        "\n",
        "    return np.array(train_images), np.array(train_labels), np.array(test_images), np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl9pstiWCP98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test = img_set(\"CNN_en_espanol/data/generated\", 20000)\n",
        "\n",
        "print(f\"Imagenes de entrenamiento: {y_train.shape}\")\n",
        "print(f\"Imagenes de test: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fUvD-R4CP-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "X_train = np.array(x_train).astype('float32')\n",
        "X_test = np.array(x_test).astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "num_classes=3\n",
        "#Y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "#Y_test = to_categorical(y_test, num_classes=num_classes)\n",
        "Y_train = y_train\n",
        "Y_test = y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IHzEv97a2lB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYU3nMyGCP-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = keras.Sequential([\n",
        "#     keras.layers.Flatten(input_shape=X_train.shape[1:]),\n",
        "#     keras.layers.Dense(128, activation=tensorflow.nn.relu),\n",
        "#     keras.layers.Dense(num_classes, activation=tensorflow.nn.softmax)\n",
        "# ])\n",
        "\n",
        "model = Sequential()\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "model.add(Conv2D(32, (3,3), input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(num_classes, input_shape=[num_classes]))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#optimizer = optimizers.Adam()\n",
        "#model.compile(loss='sparse_categorical_crossentropy',\n",
        "#             optimizer=optimizer,\n",
        "#             metrics=['accuracy'])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gc6de8KCP-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1\n",
        "batch_size = 100\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfeIlqU-6flV",
        "colab_type": "text"
      },
      "source": [
        "# Verificamos los valores de test\n",
        "\n",
        "Haremos una validación de los valores de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5yMdCOY25CZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "fig = plt.figure(figsize=(30,30))\n",
        "fig.subplots_adjust(hspace=0.3, wspace=0.1)\n",
        "rows = 10\n",
        "cols = 10\n",
        "\n",
        "# Haremos la verificación sobre las primeras 100 imagenes.\n",
        "for i in range(0,100):\n",
        "  image = x_test[i] # Leemos desde la data de prueba\n",
        "  image_array =  np.array([image]) # Preparamos el array {}\n",
        "  image = array_to_img(image) # \n",
        "  # Realizamos una predicción para esta imagen\n",
        "  predictions = model.predict(image_array) \n",
        "  prediction = np.argmax(predictions, axis=1)\n",
        "  ax = fig.add_subplot(rows, cols, i+1)\n",
        "  ax.axis('Off')\n",
        "  plt.imshow(image, interpolation=None)\n",
        "  ax.set_title(categories[prediction[0]], fontsize=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQO83BXKCP-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "def recognize_image(image_path):\n",
        "    \"\"\"\n",
        "    Esta funcion se encargara de tomar cualquier imagen\n",
        "    transformarla a un formato entendible por nuestro modelo\n",
        "    y obtener una predicción\n",
        "    \"\"\"\n",
        "    image_path = Path(image_path)\n",
        "    resized_image_path = image_path.parent/f\"resized_{image_path.name}\"\n",
        "    img = Image.open(image_path)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((IMAGE_RESIZE_PX,IMAGE_RESIZE_PX))\n",
        "    img.save(resized_image_path)\n",
        "    \n",
        "    image = load_img(resized_image_path)\n",
        "    image = img_to_array(image)\n",
        "    img_input_array = np.array([image])\n",
        "    print(img_input_array.shape)\n",
        "    predictions = model.predict(img_input_array)\n",
        "    print(predictions)\n",
        "    prediction = np.argmax(predictions, axis=1)\n",
        "    ptl.imshow(img)\n",
        "    ptl.axis('on')\n",
        "    ptl.title(categories[prediction[0]])\n",
        "    ptl.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egdhSxdmCP-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test Faciles\n",
        "!wget -O test.jpg https://pbs.twimg.com/profile_images/761195323628875776/-I0GtKkL.jpg\n",
        "#!wget -O test.jpg https://w7.pngwing.com/pngs/742/119/png-transparent-pokemon-x-and-y-pikachu-bulbasaur-pokemon-go-pikachu-carnivoran-grass-cartoon.png\n",
        "#!wget -O test.jpg https://vignette.wikia.nocookie.net/es.pokemon/images/e/e3/Squirtle.png/revision/latest?cb=20160309230820\n",
        "\n",
        "# Test dificiles\n",
        "#!wget -O test.jpg https://i.ibb.co/ctFz4My/png-transparent-pokemon-x-and-y-pikachu-bulbasaur.png\n",
        "#!wget -O test.jpg https://i.ytimg.com/vi/bRyn_aBAosM/sddefault.jpg\n",
        "#!wget -O test.jpg https://i.vimeocdn.com/portrait/5305191_300x300\n",
        "#!wget -O test.jpg  https://i.ibb.co/xqBV3SM/latest-cb-20160309230820.png\n",
        "recognize_image(\"test.jpg\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POV1lsmkrS7F",
        "colab_type": "text"
      },
      "source": [
        "# Exportar modelos\n",
        "\n",
        "Una vez tengamos un modelo entrenado podemos exportarlo para volver a utilizarlo en el futuro, o en algun otro sistema.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WEydoRkFf3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "keras_file = 'pokemon_cnn.h5'\n",
        "keras.models.save_model(model, keras_file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isawijLxF7gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import lite\n",
        "converter = lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(\"pokemon_cnn.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}